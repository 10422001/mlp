{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDataSets.MyDataSets_Subset_4.__init__\n",
      "MyDataSets.MyDataSets_Subset_9.__init__\n",
      "size = 982\n",
      "label_predicted[index] = tensor([ 0.0275, -0.3319], grad_fn=<SelectBackward0>)\n",
      "label_predicted[index].argmax(dim=0) = tensor(0)\n",
      "z_rec[0][index] = tensor([-0.4736, -0.0681], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [147]\u001B[0m, in \u001B[0;36m<cell line: 42>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabel_predicted[index]\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m) \u001B[38;5;132;01m= }\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mz_rec[\u001B[38;5;241m0\u001B[39m][index] \u001B[38;5;132;01m= }\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mint\u001B[39m(\u001B[43mclass_0_or_1_prediction\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass is 0\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: index 5 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "from torchvision.utils import save_image\n",
    "# helper.latent_rand_to_img(pick_model, rand_tensor)\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from MyDataSet import MyDataSets_Subset_4_9\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import model\n",
    "import helper\n",
    "\n",
    "pick_model = model.VaeFinal_only_one_hidden()\n",
    "pick_model = helper.import_model_name(model_x=pick_model, activate_eval=True)\n",
    "pick_2_classifier = model.MyModel5_retry_2classes_faster_4()\n",
    "pick_2_classifier = helper.import_model_name(model_x=pick_2_classifier, activate_eval=True)\n",
    "\n",
    "import MyDataSet\n",
    "\n",
    "#\n",
    "# _testset_full = datasets.MNIST(root='data/testset', train=False, transform=transforms.ToTensor(),\n",
    "#                                        download=True)\n",
    "dataset_test_4 = MyDataSet.MyDataSets_Subset_4(batch_size_train=10)\n",
    "dataset_test_9 = MyDataSet.MyDataSets_Subset_9(batch_size_train=10)\n",
    "datasetbatch_4 = next(iter(dataset_test_4.test_loader_subset_changed_labels))\n",
    "datasetbatch_9 = next(iter(dataset_test_9.test_loader_subset_changed_labels))\n",
    "\n",
    "img_to_test = datasetbatch_4[0]\n",
    "label_predicted = pick_2_classifier(img_to_test)\n",
    "z_rec = pick_model.encode(img_to_test)\n",
    "index = 5\n",
    "\n",
    "size = label_predicted.shape[0]\n",
    "class_0_or_1_prediction = label_predicted[index].argmax(dim=0)\n",
    "#pick anz numbet\n",
    "\n",
    "print(f'{size = }')\n",
    "print(f'{label_predicted[index] = }')\n",
    "print(f'{label_predicted[index].argmax(dim=0) = }')\n",
    "print(f'{z_rec[0][index] = }')\n",
    "\n",
    "if int(class_0_or_1_prediction[index]) == 0:\n",
    "    print('class is 0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import helper  # model_loaded = model.VaeMe_500_hidden()\n",
    "import model\n",
    "import torch\n",
    "\n",
    "# pick_model = model.pick_model = model.VaeFinal_only_one_hidden()\n",
    "pick_model = model.pick_model = model.VaeFinal_only_one_hidden_copy()\n",
    "pick_model = helper.import_model_name_weights_copy(model_x=pick_model, activate_eval=True)\n",
    "\n",
    "max = 4\n",
    "min = -4\n",
    "rand_tensor = (max - min) * torch.rand((1, 2)) + min\n",
    "# rand_tensor = torch.tensor((-1,-0.0))\n",
    "rand_tensor = torch.tensor((1,-0.))\n",
    "print(rand_tensor)\n",
    "\n",
    "helper.latent_rand_to_img(pick_model, rand_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from MyDataSet import MyDataSets_Subset_4_9\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Display original images\n",
    "mydatasets_subset_4_9 = MyDataSets_Subset_4_9(batch_size_train=10000)\n",
    "\n",
    "test_images_org, _ = mydatasets_subset_4_9.dataloader_test_subset_one_batch()\n",
    "test_images_copy = test_images_org.clone()\n",
    "test_images_copy_dec_end = test_images_org.clone()\n",
    "with torch.no_grad():\n",
    "    print(\"Original Images\")\n",
    "    test_images = test_images_copy.cpu()\n",
    "    test_images = test_images.clamp(0, 1)\n",
    "    test_images = test_images[:50]\n",
    "    test_images = make_grid(test_images, 10, 5)\n",
    "    test_images = test_images.numpy()\n",
    "    test_images = np.transpose(test_images, (1, 2, 0))\n",
    "    plt.imshow(test_images)\n",
    "    plt.show()\n",
    "\n",
    "# Display reconstructed images\n",
    "import helper  # model_loaded = model.VaeMe_500_hidden()\n",
    "import model\n",
    "import torch\n",
    "\n",
    "pick_model = model.VaeFinal_only_one_hidden_copy()\n",
    "pick_model = helper.import_model_name(model_x=pick_model, activate_eval=True)\n",
    "# print(test_images_org.shape)\n",
    "reconstructions, mu, sigma = pick_model(test_images_copy_dec_end)\n",
    "# print(reconstructions)\n",
    "with torch.no_grad():\n",
    "    print(\"Reconstructions\")\n",
    "    reconstructions = reconstructions.view(reconstructions.size(0), 1, 28, 28)\n",
    "    reconstructions = reconstructions.cpu()\n",
    "    reconstructions = reconstructions.clamp(0, 1)\n",
    "    reconstructions = reconstructions[:50]\n",
    "    plt.imshow(np.transpose(make_grid(reconstructions, 10, 5).numpy(), (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "eps = torch.randn_like(sigma)  # == torch.randn_like(mu) == torch.randn_like(sigma)\n",
    "print(eps)\n",
    "# eps[:] = -10\n",
    "z = mu + sigma * eps\n",
    "new_enc_dec = pick_model.decode(z)\n",
    "\n",
    "# eps = torch.rand_like(encoded[:,0])\n",
    "# print(f'{eps.shape = }')\n",
    "# print(f'{encoded.shape = }')\n",
    "# print(f'{encoded[0].shape = }')\n",
    "# print(f'{encoded[1].shape = }')\n",
    "# recon_with_vae = torch.asarray((encoded[:,0] , encoded[:,1] * eps))\n",
    "# recon_with_vae = encoded.clone()\n",
    "# recon_with_vae[:,1] = encoded[:,1] * eps\n",
    "# print(f'{recon_with_vae.shape = }')\n",
    "# recon_with_vae_model = pick_model.decode(recon_with_vae)\n",
    "# print(reconstructions)\n",
    "with torch.no_grad():\n",
    "    print(\"Reconstructions\")\n",
    "    reconstructions = new_enc_dec.view(new_enc_dec.size(0), 1, 28, 28)\n",
    "    reconstructions = reconstructions.cpu()\n",
    "    reconstructions = reconstructions.clamp(0, 1)\n",
    "    reconstructions = reconstructions[:50]\n",
    "    plt.imshow(np.transpose(make_grid(reconstructions, 10, 5).numpy(), (1, 2, 0)))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eps = torch.randn_like(sigma)  # == torch.randn_like(mu) == torch.randn_like(sigma)\n",
    "print(eps)\n",
    "eps = 0\n",
    "# eps[:] = -10\n",
    "z = mu + sigma * eps\n",
    "print(f'{z[:5] = }')\n",
    "new_enc_dec_counter = pick_model.decode(z)\n",
    "# print(f'{new_enc_dec_counter[0] = }')\n",
    "with torch.no_grad():\n",
    "    print(\"Reconstructions\")\n",
    "    print(f'{reconstructions.shape = }')\n",
    "\n",
    "    reconstructions = new_enc_dec_counter.view(new_enc_dec_counter.size(0), 1, 28, 28)\n",
    "    # print(f'{reconstructions.shape = }')\n",
    "    # reconstructions = reconstructions.cpu()\n",
    "    # print(f'{reconstructions.shape = }')\n",
    "\n",
    "    reconstructions = reconstructions.clamp(0, 1)\n",
    "    # print(f'{reconstructions.shape = }')\n",
    "    # print(f'{reconstructions = }')\n",
    "\n",
    "    reconstructions = reconstructions[:5]\n",
    "    print(f'{reconstructions.shape = }')\n",
    "\n",
    "    plt.imshow(np.transpose(make_grid(reconstructions, 10, 5).numpy(), (1, 2, 0)))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "# helper.latent_rand_to_img(pick_model, rand_tensor)\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from MyDataSet import MyDataSets_Subset_4_9\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import model\n",
    "import helper\n",
    "\n",
    "pick_model = model.VaeFinal_only_one_hidden_copy()\n",
    "pick_model = helper.import_model_name(model_x=pick_model, activate_eval=True)\n",
    "pick_2_classifier = model.MyModel5_retry_2classes_faster_4()\n",
    "pick_2_classifier = helper.import_model_name(model_x=pick_2_classifier, activate_eval=True)\n",
    "\n",
    "import MyDataSet\n",
    "\n",
    "#\n",
    "# _testset_full = datasets.MNIST(root='data/testset', train=False, transform=transforms.ToTensor(),\n",
    "#                                        download=True)\n",
    "dataset_test_4 = MyDataSet.MyDataSets_Subset_4(batch_size_train=10)\n",
    "dataset_test_9 = MyDataSet.MyDataSets_Subset_9(batch_size_train=10)\n",
    "datasetbatch_4 = next(iter(dataset_test_4.test_loader_subset_changed_labels))\n",
    "datasetbatch_9 = next(iter(dataset_test_9.test_loader_subset_changed_labels))\n",
    "\n",
    "counter4 = datasetbatch_4[0]\n",
    "counter9 = datasetbatch_9[0]\n",
    "\n",
    "img_to_test = datasetbatch_4[0]\n",
    "# img_to_test = datasetbatch_9[0]\n",
    "label_predicted = pick_2_classifier(img_to_test)\n",
    "print(f'{label_predicted = }')\n",
    "z_rec = pick_model.encode(img_to_test)\n",
    "index = 5\n",
    "\n",
    "size = label_predicted.shape[0]\n",
    "class_0_or_1_prediction = label_predicted.argmax(dim=1)\n",
    "# print(f'{class_0_or_1_prediction = }')\n",
    "\n",
    "# fig, axes = plt.subplot()\n",
    "images_testing = img_to_test[index]\n",
    "counter_image = []\n",
    "if int(class_0_or_1_prediction[index]) == 0:\n",
    "    print('class is 0')\n",
    "    print('class is \"4\"')\n",
    "    counter_image = counter9[index]\n",
    "if int(class_0_or_1_prediction[index]) == 1:\n",
    "    print('class is 1')\n",
    "    print('class is \"9\"')\n",
    "    counter_image = counter4[index]\n",
    "\n",
    "plt.imshow(img_to_test[index, 0, :, :])\n",
    "plt.imshow(counter_image[0, :, :])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PATH_SAVE_IMAGES = '/Users/dominikocsofszki/PycharmProjects/mlp/counterfactuals/save_img'\n",
    "path = Path(PATH_SAVE_IMAGES)\n",
    "with torch.no_grad():\n",
    "    reconstructions = pick_model(counter_image)[0]\n",
    "\n",
    "    print(\"Reconstructions\")\n",
    "    reconstructions = reconstructions.view(reconstructions.size(0), 1, 28, 28)\n",
    "    reconstructions = reconstructions.cpu()\n",
    "    print(reconstructions)\n",
    "    print(reconstructions)\n",
    "\n",
    "    print(reconstructions.shape, counter_image.shape, images_testing.shape)\n",
    "    grid = make_grid(tensor=[reconstructions[0], counter_image, images_testing], nrow=1, padding=5)\n",
    "    # plt.imshow(np.transpose(make_grid(tensor=[reconstructions[0],counter_image,images_testing],nrow= 1, padding=5,normalize=True).numpy(), (1, 2, 0)))\n",
    "    plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
    "    # plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
    "    # plt.imshow(np.transpose(make_grid([reconstructions[0],images_testing], 10, 5).numpy(), (1, 2, 0)))\n",
    "    #\n",
    "    plt.show()\n",
    "    save_image(tensor=grid, fp=path / 'a.png')\n",
    "\n",
    "with torch.no_grad():\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def decode_output_to_image_format(z_rec):\n",
    "    tmp = z_rec[0, :]\n",
    "    # print(tmp.shape)\n",
    "    # return z.reshape(z_rec.shape[0],28,28)\n",
    "    return tmp.reshape(z_rec.shape[0], 28, 28)\n",
    "\n",
    "\n",
    "def print_grid(images):\n",
    "    if isinstance(images, tuple):\n",
    "        # if isinstance(images,list):\n",
    "        images = [torch.tensor(decode_output_to_image_format(x)) for x in images]\n",
    "        print('    if isinstance(images,tuple):')\n",
    "    with torch.no_grad():\n",
    "        # reconstructions = pick_model(counter_image)[0]\n",
    "        #\n",
    "        # print(\"Reconstructions\")\n",
    "        # reconstructions = reconstructions.view(reconstructions.size(0), 1, 28, 28)\n",
    "        # reconstructions = reconstructions.cpu()\n",
    "        # print(reconstructions)\n",
    "        # print(reconstructions)\n",
    "        images = [torch.tensor(decode_output_to_image_format(x)) for x in images]\n",
    "        # images = images.view(-1,1,28,28)\n",
    "        # resize_images = images.view(28,28)\n",
    "        # grid = make_grid(tensor=resize_images,nrow= 5, padding=5)\n",
    "\n",
    "        # print(reconstructions.shape,counter_image.shape,images_testing.shape)\n",
    "        # grid = make_grid(tensor=[reconstructions[0],counter_image,images_testing],nrow= 1, padding=5)\n",
    "\n",
    "        grid = make_grid(tensor=images, nrow=5, padding=5)\n",
    "\n",
    "        # plt.imshow(np.transpose(make_grid(tensor=[reconstructions[0],counter_image,images_testing],nrow= 1, padding=5,normalize=True).numpy(), (1, 2, 0)))\n",
    "        plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
    "        # plt.imshow(np.transpose(make_grid([reconstructions[0],images_testing], 10, 5).numpy(), (1, 2, 0)))\n",
    "        plt.show()\n",
    "        # save_image(tensor = grid,fp = path/'a.png')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = datasetbatch_4[:1][0]\n",
    "# print_grid(images=datasetbatch_4[0][:1])\n",
    "print_grid(images=images)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_diff_img(image_rec, mu, sigma):\n",
    "    with torch.no_grad():\n",
    "        eps = torch.randn_like(sigma)\n",
    "        z = mu + sigma * eps\n",
    "        img_reconstructed = pick_model.decode(z)\n",
    "\n",
    "\n",
    "def generate_x_images_of_one_image(images, nr_of_gen=5):\n",
    "    # eps = torch.arange(start =-4,end=4,step =0.3)\n",
    "    pick_model.eval()\n",
    "    image_rec, mu, sigma = pick_model(images)\n",
    "    print(f'{sigma = }')\n",
    "    print(f'{mu = }')\n",
    "    arr_with_z = []\n",
    "    arr_rec_images = []\n",
    "    tensor_rec_images = torch.empty(size=(nr_of_gen, 28 * 28))\n",
    "    print(tensor_rec_images)\n",
    "    print(tensor_rec_images.shape)\n",
    "    for i in range(nr_of_gen):\n",
    "        eps = torch.randn_like(input=sigma)\n",
    "        print(f'{eps = }')\n",
    "        z = mu + sigma * eps\n",
    "        rec_image = pick_model.decode(z)\n",
    "        print(f'{rec_image.shape = }')\n",
    "        tensor_rec_images[i] = rec_image\n",
    "        # arr_rec_images[:,i] = rec_image\n",
    "    # print(arr_with_z)\n",
    "    # print(arr_rec_images[0].shape)\n",
    "    # x = [x.detach().numpy() for x in arr_rec_images]\n",
    "    # y = torch.from_numpy(arr_rec_images)\n",
    "    # print(x)\n",
    "    # print_grid(images=x)\n",
    "    print(f'{tensor_rec_images.shape = }')\n",
    "    print_grid(images=tensor_rec_images)\n",
    "    print(f'{image_rec = }')\n",
    "    # print_grid(images=arr_rec_images)\n",
    "\n",
    "    '''print(f'{image_rec.shape = }')\n",
    "    images_rec_vect = torch.zeros(count)\n",
    "    print(f'{images_rec_vect = }')\n",
    "    images_rec_vect[:] = mu[0]\n",
    "    print(f'{images_rec_vect = }')\n",
    "\n",
    "    images_rec_vect.new_full((5,1), image_rec[0])\n",
    "    print(images_rec_vect)\n",
    "    print(f'{images_rec_vect.shape}')\n",
    "    images_rec_vect[:count] = image_rec\n",
    "    print(images_rec_vect)\n",
    "    for _ in count:\n",
    "        img_reconstructed = generate_diff_img(image_rec,mu,sigma)\n",
    "'''\n",
    "\n",
    "\n",
    "generate_x_images_of_one_image(images)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def decode_output_to_image_format(z_rec):\n",
    "    tmp = z_rec[0, :]\n",
    "    print(tmp.shape)\n",
    "    # return z.reshape(z_rec.shape[0],28,28)\n",
    "    return tmp.reshape(z_rec.shape[0], 28, 28)\n",
    "\n",
    "\n",
    "def print_grid(images):\n",
    "    if isinstance(images, tuple):\n",
    "        images = [torch.tensor(decode_output_to_image_format(x)) for x in images]\n",
    "        print('    if isinstance(images,tuple):')\n",
    "    with torch.no_grad():\n",
    "        grid = make_grid(tensor=images, nrow=5, padding=5)\n",
    "        plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
    "        plt.show()\n",
    "        # save_image(tensor = grid,fp = path/'a.png')\n",
    "\n",
    "\n",
    "# def return_new\n",
    "img_4_batch, label_4_batch = next(iter(dataset_test_4.dataloader_test_subset()))\n",
    "img_9_batch, label_9_batch = next(iter(dataset_test_9.dataloader_test_subset()))\n",
    "X = next(iter(dataset_test_9.dataloader_test_subset()))\n",
    "images = img_4_batch[:10]\n",
    "print(images.shape)\n",
    "print_grid(images=images)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def generate_diff_img(image_rec,mu,sigma) :\n",
    "#     with torch.no_grad():\n",
    "#         eps = torch.randn_like(sigma)\n",
    "#         z = mu+ sigma * eps\n",
    "#         img_reconstructed = pick_model.decode(z)\n",
    "\n",
    "def generate_x_images_of_one_image(images, pick_model, nr_of_gen=5, factor=1):\n",
    "    with torch.no_grad():\n",
    "        image_rec, mu, sigma = pick_model(images)\n",
    "        # print(f'{sigma = }')\n",
    "        # print(f'{mu = }')\n",
    "        eps = torch.randn(nr_of_gen, 2) * factor\n",
    "        # print(f'{image_rec.shape = }')\n",
    "        z = mu + sigma * eps\n",
    "        # print(f'{z.shape = }')\n",
    "        # print(f'{z = }')\n",
    "\n",
    "        new_images = pick_model.decode(z)\n",
    "        # print(f'{new_images.shape = }')\n",
    "        print_grid(images=new_images.view(-1, 1, 28, 28))\n",
    "\n",
    "\n",
    "img = img_4_batch[0, :, :, :]\n",
    "# print_grid(images=img_4_batch[:1,:,:,:])\n",
    "# print_grid(images=img)\n",
    "pick_model = model.VaeFinal_only_one_hidden_copy()\n",
    "pick_model = helper.import_model_name(model_x=pick_model, activate_eval=True)\n",
    "img_counterfactuals = generate_x_images_of_one_image(images=img, nr_of_gen=5, pick_model=pick_model, factor=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import model\n",
    "\n",
    "pick_model = model.VaeFinal_only_one_hidden_copy()\n",
    "# pick_model = model.VaeFinal_only_one_hidden_copy()\n",
    "pick_model = helper.import_model_name(model_x=pick_model, activate_eval=True)\n",
    "# for factor_step in range(-4,4) :\n",
    "#     generate_x_images_of_one_image(images = img, nr_of_gen=10,pick_model = pick_model,factor=factor_step)\n",
    "img_ = img_4_batch[1, :, :, :]\n",
    "plt.imshow(img_[0, :, :])\n",
    "for factor_step in range(-4, 4):\n",
    "    generate_x_images_of_one_image(images=img_, nr_of_gen=5, pick_model=pick_model, factor=factor_step)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def decode_output_to_image_format(z_rec):\n",
    "    tmp = z_rec[0, :]\n",
    "    # print(tmp.shape)\n",
    "    # return z.reshape(z_rec.shape[0],28,28)\n",
    "    return tmp.reshape(z_rec.shape[0], 28, 28)\n",
    "\n",
    "\n",
    "def print_grid_refactor(images):\n",
    "    with torch.no_grad():\n",
    "        # images = [torch.tensor(decode_output_to_image_format(x)) for x in images]\n",
    "        grid = make_grid(tensor=images, nrow=5, padding=5, normalize=True, value_range=(0, 1))\n",
    "        plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
    "        plt.show()\n",
    "        # save_image(tensor = grid,fp = path/'a.png')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import model\n",
    "import helper\n",
    "\n",
    "\n",
    "def generate_x_images_of_one_image_refactor(images, pick_model, nr_of_gen=5, factor=1):\n",
    "    with torch.no_grad():\n",
    "        image_rec, mu, sigma = pick_model(images)\n",
    "        eps = torch.randn(nr_of_gen, 2) * factor\n",
    "        z = mu + sigma * eps\n",
    "        new_images = pick_model.decode(z)\n",
    "        print_grid_refactor(images=new_images.view(-1, 1, 28, 28))\n",
    "\n",
    "\n",
    "def generate_x_images_of_one_image_towards_counterfactual(images, pick_model, nr_of_gen=5, factor=1):\n",
    "    with torch.no_grad():\n",
    "        image_rec, mu, sigma = pick_model(images)\n",
    "        eps = torch.randn(nr_of_gen, 2) * factor\n",
    "        z = mu + sigma * eps\n",
    "        new_images = pick_model.decode(z)\n",
    "        print_grid_refactor(images=new_images.view(-1, 1, 28, 28))\n",
    "\n",
    "\n",
    "def generate_x_images_towards_linear_border(images, pick_model, nr_of_gen=5, factor=1):\n",
    "    with torch.no_grad():\n",
    "        steps = torch.empty(nr_of_gen)\n",
    "        ones = torch.ones(nr_of_gen)\n",
    "        torch.fill(steps, factor)\n",
    "        image_rec, mu, sigma = pick_model(images)\n",
    "        print(mu)\n",
    "        mu = mu.squeeze(dim=0)\n",
    "        sigma = sigma.squeeze(dim=0)\n",
    "        (z) = mu[0]*ones + sigma[0]*0, mu[1]+sigma[1]*steps\n",
    "        (z) = mu[0]*ones, mu[1]+sigma[1]*steps\n",
    "        z = torch.vstack(z)\n",
    "        z = torch.t(z)\n",
    "        new_images = pick_model.decode(z)\n",
    "        print_grid_refactor(images=new_images.view(-1, 1, 28, 28))\n",
    "\n",
    "\n",
    "model_copy = model.VaeFinal_only_one_hidden_copy()\n",
    "model_copy = helper.import_model_name_weights_copy(model_x=model_copy, activate_eval=True)\n",
    "\n",
    "img_ = img_4_batch[1, :, :, :]\n",
    "plt.imshow(img_[0, :, :])\n",
    "for factor_step in range(-4, 4):\n",
    "    generate_x_images_towards_linear_border(images=img_, nr_of_gen=5, pick_model=model_copy, factor=factor_step)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import helper  # model_loaded = model.VaeMe_500_hidden()\n",
    "import model\n",
    "import torch\n",
    "\n",
    "# pick_model = model.pick_model = model.VaeFinal_only_one_hidden()\n",
    "pick_model = model.pick_model = model.VaeFinal_only_one_hidden_copy()\n",
    "pick_model = helper.import_model_name_weights_copy(model_x=pick_model, activate_eval=True)\n",
    "\n",
    "max = 4\n",
    "min = -4\n",
    "# rand_tensor = (max - min) * torch.rand((1, 2)) + min\n",
    "# rand_tensor = torch.tensor((-1,-0.0))\n",
    "rand_tensor = torch.tensor((1,-0.))\n",
    "print(rand_tensor)\n",
    "\n",
    "helper.latent_rand_to_img(pick_model, rand_tensor)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_4_batch, label_4_batch = next(iter(dataset_test_4.dataloader_test_subset()))\n",
    "img_9_batch, label_9_batch = next(iter(dataset_test_9.dataloader_test_subset()))\n",
    "print(img_4_batch.shape)\n",
    "print(img_9_batch.shape)\n",
    "print(img_4_batch.mean())\n",
    "print(img_9_batch.mean())\n",
    "rec4,mu4,sigma4 = model_copy(img_4_batch)\n",
    "rec9,mu9,sigma9 = model_copy(img_9_batch)\n",
    "mu4_mean = mu4.mean(dim=0)\n",
    "mu9_mean = mu9.mean(dim=0)\n",
    "print(mu4.mean(dim=0))\n",
    "print(mu9.mean(dim=0))\n",
    "print(mu9.mean(dim=0))\n",
    "\n",
    "dif_mean = mu4_mean-mu9_mean\n",
    "print(f'{dif_mean = }')\n",
    "print(f'{mu4[0]}')\n",
    "print(f'{mu4[0].shape}')\n",
    "helper.latent_rand_to_img(modelpick=model_copy,tensor_rand=mu4[0])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "helper.latent_rand_to_img(modelpick=model_copy,tensor_rand=mu4[200]-dif_mean)\n",
    "def calc_counter_factual(latent_input,dif_mean,step) :\n",
    "    return latent_input - dif_mean/100 * step\n",
    "helper.latent_rand_to_img(modelpick=model_copy,tensor_rand=calc_counter_factual(mu4[0],dif_mean,step=30))\n",
    "print(f'{dif_mean = }')\n",
    "print(f'{mu4[0] = }')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model_copy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
